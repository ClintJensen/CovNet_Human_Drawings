{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_training_hyperparameter_optimization.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pabloinsente/CovNet_Human_Drawings/blob/master/model_training_hyperparameter_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "PXwZd3tQMQgU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# install seaborn for pairplot\n",
        "! pip install -q seaborn\n",
        "! pip install talos\n",
        "\n",
        "\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import csv\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)\n",
        "print(tf.test.gpu_device_name())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LmQPGeHVMvFv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import talos as ta\n",
        "\n",
        "from keras.activations import relu, elu\n",
        "\n",
        "p = {'first_neuron': [4, 8, 16, 32, 64],\n",
        "     'activation': [relu, elu],\n",
        "     'optimizer': ['Nadam', 'Adam']\n",
        "     'losses':['binary_crossentropy', 'logcosh'],\n",
        "     'hidden_layers':[0, 1, 2],\n",
        "     'batch_size': [10, 20, 30],\n",
        "     'epochs':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "     'lr':[0.0001, 0.001, 0.001, 0.01],\n",
        "     'last_activation': ['sigmoid'],\n",
        "\n",
        "}\n",
        "\n",
        "input_dim = SOMETHING\n",
        "output_activation = 'sigmoid'\n",
        "\n",
        "def input_model(x_train, y_train, xval, y_val, params):\n",
        "  # define model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(params['first_neuron'], input_dim=input_dim, activation=params['activation']))\n",
        "  model.add(Dense(1,activation=params['last_activation']))\n",
        "  model.compile(loss=['losses'],\n",
        "                optimizer=params['optimizer'](lr_normalizer(params['lr'], params['optimizer'])),\n",
        "                metrics=['accuracy'])\n",
        "  # train model\n",
        "  out = model.fit(x_train, y_train,\n",
        "                 batch_size=params['batch_size'],\n",
        "                 epochs=params['epochs'],\n",
        "                 validation_data=[x_val, y_val])\n",
        "\n",
        "  return out, model\n",
        "\n",
        "# x = prediction features\n",
        "# y = prediction outcome variable\n",
        "\n",
        "# \n",
        "ta.Scan(x, y,\n",
        "     params=p,\n",
        "     model=input_model,\n",
        "     grid_downsample=.1,\n",
        "     random_method=quantum)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}