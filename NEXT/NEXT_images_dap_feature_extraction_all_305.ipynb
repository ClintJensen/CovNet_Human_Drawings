{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "NEXT_images dap_feature_extraction_all_305.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ClintJensen/CovNet_Human_Drawings/blob/master/NEXT_images_dap_feature_extraction_all_305.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szpI00RBqdj1"
      },
      "source": [
        "# Feature extraction from all kids images with block5 max pool layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db2ABhX0qdj7"
      },
      "source": [
        "# Here we use tensorflow.keras API to process the data by using VGG19 \n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# to import filenames\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "# to handle data\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFAvjsQTqdj8",
        "outputId": "b248da97-7584-472d-e978-a46f133ffd0b"
      },
      "source": [
        "# Load base model with imagenet pre-trained weights \n",
        "base_model = VGG19(weights='imagenet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
            "574717952/574710816 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv-ELMqKqdj9",
        "outputId": "b7791107-1ba0-48fa-8778-d0cad5e2ceba"
      },
      "source": [
        "# Here we can see the progression from layer to layer \n",
        "# The output shape column shows how the image gets compressed as \n",
        "# it pass through the layers\n",
        "base_model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 143,667,240\n",
            "Trainable params: 143,667,240\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOU6I4E5qdj-"
      },
      "source": [
        "## Feature extraction for a single image with block5 max pool layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsmmm36tqdj-",
        "outputId": "e06a6e20-f4ca-4b38-9400-8465ba03c968"
      },
      "source": [
        "####################################\n",
        "# To get the data If you're in Colab\n",
        "####################################\n",
        "\n",
        "# Images are storage in GitHub. By running this we clone the data into Colab\n",
        "! git clone https://github.com/ClintJensen/CovNet_Human_Drawings\n",
        "# Run this just once per sesion\n",
        "\n",
        "# Now repo data is available in Colab local environment\n",
        "!ls CovNet_Human_Drawings/data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CovNet_Human_Drawings'...\n",
            "remote: Enumerating objects: 132, done.\u001b[K\n",
            "remote: Counting objects: 100% (132/132), done.\u001b[K\n",
            "remote: Compressing objects: 100% (132/132), done.\u001b[K\n",
            "remote: Total 1332 (delta 86), reused 0 (delta 0), pack-reused 1200\u001b[K\n",
            "Receiving objects: 100% (1332/1332), 119.94 MiB | 32.21 MiB/s, done.\n",
            "Resolving deltas: 100% (499/499), done.\n",
            "Checking out files: 100% (1490/1490), done.\n",
            "cluster-dataframes   dap-metadata-kids\tmerged-dataframes-prediction\n",
            "dap-drawings-adults  DAP_NEXT_Images\toptimization-results\n",
            "dap-drawings-all     edit-csv\t\tREADME.md\n",
            "dap-drawings-kids    edit-filenames\tvectors-features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lho19gyjrk-z",
        "outputId": "4039f83e-2f07-48f2-bc0a-eda5dff26498"
      },
      "source": [
        "ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mCovNet_Human_Drawings\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP7BdIMOqdj-",
        "outputId": "86a0f5b8-1049-4b66-8f90-f5e299260b50"
      },
      "source": [
        "#/content/CovNet_Human_Drawings/data/DAP_NEXT_Images\n",
        "# Print filenames on DAP_NEXT_Images\n",
        "!ls ../content/CovNet_Human_Drawings/data/DAP_NEXT_Images | head"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DAM001_F_DAPedit.jpg\n",
            "DAM001_P_DAPedit.jpg\n",
            "DAM001_T_DAPedit.jpg\n",
            "DAM002_F_DAPedit.jpg\n",
            "DAM002_P_DAPedit.jpg\n",
            "DAM002_T_DAPedit.jpg\n",
            "DAM003_F_DAPedit.jpg\n",
            "DAM003_P_DAPedit.jpg\n",
            "DAM003_T_DAPedit.jpg\n",
            "DAM004_F_DAPedit.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnbcnzKFqdj_"
      },
      "source": [
        "# Load and reshape the image to be feed into the model\n",
        "img_path = '../content/CovNet_Human_Drawings/data/DAP_NEXT_Images/DAM001_F_DAPedit.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIjZrGyTqdj_"
      },
      "source": [
        "#######################################\n",
        "# Select a layer for feature extraction\n",
        "#######################################\n",
        "\n",
        "# Here we pick the maxpooling layer in block 5\n",
        "feature_layer = \"block5_pool\"\n",
        "\n",
        "# To check other layers\n",
        "# feature_layer = \"block1_pool \"\n",
        "# feature_layer = \"block1_conv1 \"\n",
        " \n",
        "model = Model(inputs=base_model.input, \n",
        "              outputs=base_model.get_layer(feature_layer).output)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDayZy6_qdj_"
      },
      "source": [
        "#####################################################\n",
        "# Do the feature extraction with block5 pooling layer\n",
        "#####################################################\n",
        "\n",
        "block5_pool_features = model.predict(x)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V92K6ym3qdkA",
        "outputId": "51899a6f-ce5a-43fc-e0bd-487f053fba0f"
      },
      "source": [
        "# In block 5, we can check that feature has the same shape that the maxpooling \n",
        "# layer in block 5 (above drawing)\n",
        "\n",
        "# Print tensor shape\n",
        "block5_pool_features.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 7, 7, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jenneDA7qdkA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45e44409-6c60-490f-e29a-67d324892939"
      },
      "source": [
        "# Print extracted feature as a tensor (i.e., feature)\n",
        "#print(block5_pool_features)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[ 0.         0.         0.        ...  0.         3.044863\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  0.         0.7641097\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   ...\n",
            "   [ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  0.         1.377389\n",
            "     0.       ]]\n",
            "\n",
            "  [[ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   ...\n",
            "   [ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   [ 1.8787315  0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]]\n",
            "\n",
            "  [[ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   ...\n",
            "   [ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   [ 0.6480696  0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  0.         0.8351585\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  1.3075179  0.\n",
            "     0.       ]\n",
            "   ...\n",
            "   [ 2.522842   0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  0.         0.8936795\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]]\n",
            "\n",
            "  [[ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  0.         4.5014668\n",
            "     0.       ]\n",
            "   [17.916348   0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   ...\n",
            "   [26.39381    0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]]\n",
            "\n",
            "  [[ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   [33.72244    0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   ...\n",
            "   [12.29667    0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]\n",
            "   [ 0.         0.         0.        ...  0.         0.\n",
            "     0.       ]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZT8hIc6qdkA",
        "outputId": "35c5305f-b88a-4422-bee0-7d93a57b0646"
      },
      "source": [
        "# Print extracted feature flattened as a 1D vector\n",
        "vgg19_feature_np = np.array(block5_pool_features)\n",
        "vgg19_feature_np.flatten()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IIDoEsTqdkB"
      },
      "source": [
        "## Feature extraction from ALL images with block5 max pool layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqfi18M2qdkB",
        "outputId": "b330c818-2d19-4867-e35c-29caaa4299f2"
      },
      "source": [
        "# Get the drawings filenames from directory \n",
        "\n",
        "# If relative path doesn't work, change path as nedeed\n",
        "path = '../content/CovNet_Human_Drawings/data/DAP_NEXT_Images/'\n",
        "filenames = [f for f in listdir(path) if isfile(join(path, f))]\n",
        "len(filenames) # This should yield 305"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "305"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMxZdW7GqdkB"
      },
      "source": [
        "#########################################\n",
        "# Select the layer for feature extraction\n",
        "#########################################\n",
        "\n",
        "# A list of the layers' names is obtained by running \"base_model.summary()\"\n",
        "feature_layer = \"block5_pool\" # let's take the last max pool as example\n",
        "model = Model(inputs=base_model.input, \n",
        "              outputs=base_model.get_layer(feature_layer).output)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8wts9XEqdkB"
      },
      "source": [
        "##########################################\n",
        "# Do the feature extraction for all images\n",
        "##########################################\n",
        "\n",
        "# Let's create a list to save flattened tensors as vectors\n",
        "vgg19_feature_list = []\n",
        "\n",
        "# Loop over filenames and append flattened tensor to vector list\n",
        "for fname in filenames:\n",
        "  # This part of the loop reshapes and preprocesses the input images \n",
        "  img_path = path + fname\n",
        "  img = image.load_img(img_path, target_size=(224, 224))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  x = preprocess_input(x)\n",
        "  \n",
        "  # This part of the loop extracts the features and flattens the tensors to vectors\n",
        "  vgg19_feature = model.predict(x)\n",
        "  vgg19_feature_np = np.array(vgg19_feature)\n",
        "  vgg19_feature_list.append(vgg19_feature_np.flatten())"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcAfLtgzqdkC",
        "outputId": "35071ebe-0cf7-4148-fbb5-ba93d1b25913"
      },
      "source": [
        "##############################################\n",
        "# Pass the VGG19 feature list to a numpy array\n",
        "##############################################\n",
        "\n",
        "vgg19_feature_list_np = np.array(vgg19_feature_list)\n",
        "print(type(vgg19_feature_list_np))\n",
        "print(vgg19_feature_list_np.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(305, 25088)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyUoShDpqdkC"
      },
      "source": [
        "###################################\n",
        "# Export numpy array as a .npy file\n",
        "###################################\n",
        "\n",
        "#.npy files are lightweight and easier to load back on python\n",
        "\n",
        "save_path = '../content/CovNet_Human_Drawings/data/vectors-features/'\n",
        "filename = 'vgg19_vectors_drawings_block5_pool_all_305_raw'\n",
        "np.save(save_path+filename, vgg19_feature_list_np)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3zlYr5cqdkC"
      },
      "source": [
        "##################################\n",
        "# Export numpy array as a csv file\n",
        "##################################\n",
        "\n",
        "# If you save np arrays as .csv files, they will be very heavy\n",
        "# zip files afterwards to avoid conflicts on GitHub (100mg limit upstream)\n",
        "\n",
        "save_path = '../content/CovNet_Human_Drawings/data/vectors-features/'\n",
        "filename = 'vgg19_vectors_drawings_block5_pool_all_305_raw.csv'\n",
        "np.savetxt(save_path+filename, vgg19_feature_list_np, delimiter=\",\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vos53wAAExD-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
