{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction from all kids images with block5 max pool layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use tensorflow.keras API to process the data by using VGG19 \n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# to import filenames\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# to handle data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base model with imagenet pre-trained weights \n",
    "base_model = VGG19(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Here we can see the progression from layer to layer \n",
    "# The output shape column shows how the image gets compressed as \n",
    "# it pass through the layers\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction for a single image with block5 max pool layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# To get the data If you're in Colab\n",
    "####################################\n",
    "\n",
    "# Images are storage in GitHub. By running this we clone the data into Colab\n",
    "# ! git clone https://github.com/pabloinsente/CovNet_Human_Drawings\n",
    "# Run this just once per sesion\n",
    "\n",
    "# Now repo data is available in Colab local environment\n",
    "# !ls CovNet_Human_Drawings/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAM001_F.jpg\n",
      "DAM001_P.jpg\n",
      "DAM001_T.jpg\n",
      "DAM002_F.jpg\n",
      "DAM002_P.jpg\n",
      "DAM002_T.jpg\n",
      "DAM003_F.jpg\n",
      "DAM003_P.jpg\n",
      "DAM003_T.jpg\n",
      "DAM004_F.jpg\n"
     ]
    }
   ],
   "source": [
    "# Print filenames on dap-drawings-kids\n",
    "!ls ../data/dap-drawings-kids | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and reshape the image to be feed into the model\n",
    "img_path = '../data/dap-drawings-kids/DAM001_F.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Select a layer for feature extraction\n",
    "#######################################\n",
    "\n",
    "# Here we pick the maxpooling layer in block 5\n",
    "feature_layer = \"block5_pool\"\n",
    "\n",
    "# To check other layers\n",
    "# feature_layer = \"block1_pool \"\n",
    "# feature_layer = \"block1_conv1 \"\n",
    " \n",
    "model = Model(inputs=base_model.input, \n",
    "              outputs=base_model.get_layer(feature_layer).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# Do the feature extraction with block5 pooling layer\n",
    "#####################################################\n",
    "\n",
    "block5_pool_features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7, 7, 512)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In block 5, we can check that feature has the same shape that the maxpooling \n",
    "# layer in block 5 (above drawing)\n",
    "\n",
    "# Print tensor shape\n",
    "block5_pool_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print extracted feature as a tensor (i.e., feature)\n",
    "# print(block5_pool_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print extracted feature flattened as a 1D vector\n",
    "vgg19_feature_np = np.array(block5_pool_features)\n",
    "vgg19_feature_np.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction from ALL images with block5 max pool layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the drawings filenames from directory \n",
    "\n",
    "# If relative path doesn't work, change path as nedeed\n",
    "path = '../data/dap-drawings-kids/'\n",
    "filenames = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "len(filenames) # This should yield 257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Select the layer for feature extraction\n",
    "#########################################\n",
    "\n",
    "# A list of the layers' names is obtained by running \"base_model.summary()\"\n",
    "feature_layer = \"block5_pool\" # let's take the last max pool as example\n",
    "model = Model(inputs=base_model.input, \n",
    "              outputs=base_model.get_layer(feature_layer).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Do the feature extraction for all images\n",
    "##########################################\n",
    "\n",
    "# Let's create a list to save flattened tensors as vectors\n",
    "vgg19_feature_list = []\n",
    "\n",
    "# Loop over filenames and append flattened tensor to vector list\n",
    "for fname in filenames:\n",
    "  # This part of the loop reshape and preprocess the input images \n",
    "  img_path = path + fname\n",
    "  img = image.load_img(img_path, target_size=(224, 224))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  \n",
    "  # This part of the loop extract the featues and flatten the tensors to vectors\n",
    "  vgg19_feature = model.predict(x)\n",
    "  vgg19_feature_np = np.array(vgg19_feature)\n",
    "  vgg19_feature_list.append(vgg19_feature_np.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(257, 25088)\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "# Pass the VGG19 feature list to a numpy array\n",
    "##############################################\n",
    "\n",
    "vgg19_feature_list_np = np.array(vgg19_feature_list)\n",
    "print(type(vgg19_feature_list_np))\n",
    "print(vgg19_feature_list_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Export numpy array as a .npy file\n",
    "###################################\n",
    "\n",
    "#.npy files are lightweight and easier to load back on python\n",
    "\n",
    "save_path = '../data/vectors-features/'\n",
    "filename = 'vgg19_vectors_drawings_block5_pool_kids_257_raw'\n",
    "np.save(save_path+filename, vgg19_feature_list_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Export numpy array as a csv file\n",
    "##################################\n",
    "\n",
    "# If you save np arrays as .csv files, they will be very heavy\n",
    "# zip files afterwards to avoid conflicts on GitHub (100mg limit upstream)\n",
    "\n",
    "save_path = '../data/vectors-features/'\n",
    "filename = 'vgg19_vectors_drawings_block5_pool_kids_257_raw.csv'\n",
    "np.savetxt(save_path+filename, vgg19_feature_list_np, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
