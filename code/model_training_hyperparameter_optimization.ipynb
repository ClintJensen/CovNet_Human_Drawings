{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_training_hyperparameter_optimization.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pabloinsente/CovNet_Human_Drawings/blob/master/code/model_training_hyperparameter_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "3oEwJCxQRSIn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1164
        },
        "outputId": "0d912f5d-63fa-44be-ce3e-0ef2c015e836"
      },
      "cell_type": "code",
      "source": [
        "!pip install talos"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting talos\n",
            "  Downloading https://files.pythonhosted.org/packages/74/26/c44a51af579835c873e878b99c68fcba08107cdfc22d72ac4ecbc027f158/talos-0.4.9.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from talos) (1.16.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from talos) (0.23.4)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from talos) (2.2.4)\n",
            "Collecting astetik (from talos)\n",
            "  Downloading https://files.pythonhosted.org/packages/03/c7/d074a03a59f55708cacb875c008bf375028c452a1ffcc452762a3c3dfed2/astetik-1.9.8.tar.gz\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from talos) (0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from talos) (4.28.1)\n",
            "Collecting chances (from talos)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/8a/e0ce40affac9c5292da615375cd2ce979728b8f5a5d3afd4a9e3acdf9166/chances-0.1.6.tar.gz (45kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 20.8MB/s \n",
            "\u001b[?25hCollecting kerasplotlib (from talos)\n",
            "  Downloading https://files.pythonhosted.org/packages/e8/2e/b8628bfef6a817da9be863f650cf67187676b10d27d94b23f248da35d2b4/kerasplotlib-0.1.4.tar.gz\n",
            "Collecting wrangle (from talos)\n",
            "  Downloading https://files.pythonhosted.org/packages/71/9b/11fec37414435e24d2592672540a1c3e358c35fe05a98c8df2e08df91000/wrangle-0.6.2.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from talos) (2.18.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->talos) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->talos) (2018.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->talos) (1.11.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->talos) (1.0.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->talos) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->talos) (1.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->talos) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->talos) (1.2.1)\n",
            "Collecting geonamescache (from astetik->talos)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/66/586b63536bc578a6d28ffc1114959f51b2ca1a9582f9b987206b3ba9aa86/geonamescache-1.0.1-py3-none-any.whl (775kB)\n",
            "\u001b[K    100% |████████████████████████████████| 778kB 20.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->talos) (0.20.3)\n",
            "Collecting matplotlib==2.2.3 (from chances->talos)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/59/f235ab21bbe7b7c6570c4abf17ffb893071f4fa3b9cf557b09b60359ad9a/matplotlib-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (12.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 12.6MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from wrangle->talos) (0.8.0)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (2.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.3->chances->talos) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.3->chances->talos) (2.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.3->chances->talos) (1.0.1)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.6/dist-packages (from statsmodels->wrangle->talos) (0.5.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib==2.2.3->chances->talos) (40.9.0)\n",
            "Building wheels for collected packages: talos, astetik, chances, kerasplotlib, wrangle\n",
            "  Building wheel for talos (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/eb/6b/c0/5b58a4767728bb467656ccd70b4fc2e286840c1e8ffa2631ac\n",
            "  Building wheel for astetik (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ba/cc/e9/11c6a853d8379f295e17b68f2139ea1bbcd13c5b260822abc7\n",
            "  Building wheel for chances (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/61/12/37/957767d4ed95919b90081079c6eb74f83927930e652b30fa93\n",
            "  Building wheel for kerasplotlib (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/36/6b/4c/e1fc6d7d8811940fbea1147b1519c7baa6933e4baeff904433\n",
            "  Building wheel for wrangle (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ce/ea/67/c7756f897f70f22279c7f2bbf5be52423d85835643042fcc34\n",
            "Successfully built talos astetik chances kerasplotlib wrangle\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: wrangle, geonamescache, astetik, matplotlib, chances, kerasplotlib, talos\n",
            "  Found existing installation: matplotlib 3.0.3\n",
            "    Uninstalling matplotlib-3.0.3:\n",
            "      Successfully uninstalled matplotlib-3.0.3\n",
            "Successfully installed astetik-1.9.8 chances-0.1.6 geonamescache-1.0.1 kerasplotlib-0.1.4 matplotlib-2.2.3 talos-0.4.9 wrangle-0.6.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "LVwIGgW9N9v7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "d79fb4b3-6230-4ff2-d0a2-1bb2997d4279"
      },
      "cell_type": "code",
      "source": [
        "import talos as ta\n",
        "from talos.metrics.keras_metrics import fmeasure_acc\n",
        "from talos.model.normalizers import lr_normalizer\n",
        "\n",
        "from keras.activations import relu, elu, sigmoid\n",
        "from keras.optimizers import Adam, Nadam, RMSprop\n",
        "from keras.losses import binary_crossentropy, logcosh\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "from numpy import genfromtxt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
            "  from pandas.core import datetools\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "oGx8tVOIQ_6U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "d1822368-110f-4c0c-925e-f52cd33cf8b2"
      },
      "cell_type": "code",
      "source": [
        "# Clone the data into Colab\n",
        "! git clone https://github.com/pabloinsente/CovNet_Human_Drawings"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CovNet_Human_Drawings'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 584 (delta 25), reused 25 (delta 9), pack-reused 527\u001b[K\n",
            "Receiving objects: 100% (584/584), 54.96 MiB | 27.96 MiB/s, done.\n",
            "Resolving deltas: 100% (135/135), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MU75iiW7VYIj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "76cce42e-e372-46f2-900f-50a37f205230"
      },
      "cell_type": "code",
      "source": [
        "# Get data\n",
        "x_path= 'CovNet_Human_Drawings/data/merged_dataframes_prediction/x_train_drawings_features_max_pool_5_pca.csv'\n",
        "y_path = 'CovNet_Human_Drawings/data/merged_dataframes_prediction/y_train_age_adult_labels.csv'\n",
        "\n",
        "x = genfromtxt(x_path, delimiter=',')\n",
        "y = genfromtxt(y_path, delimiter=',')\n",
        "\n",
        "print(x.shape) # (258, 200)\n",
        "print(y.shape) # (258,)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(258, 200)\n",
            "(258,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IjFd7wkTjvk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "2677dfec-7a7e-4f84-8d65-64c438b50d72"
      },
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "# Since we have an small sample, we will do a 70/30 split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state=44)\n",
        "print(x_train.shape) # (180, 200)\n",
        "print(y_train.shape) # (180,)\n",
        "print(x_test.shape) # (78, 200)\n",
        "print(y_test.shape) # (78,)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(180, 200)\n",
            "(180,)\n",
            "(78, 200)\n",
            "(78,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LmQPGeHVMvFv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define model\n",
        "def input_model(x_train, y_train, x_val, y_val, params):\n",
        "  model = Sequential()\n",
        "  # add hidden layer\n",
        "  model.add(Dense(params['first_neuron'], \n",
        "                  input_dim=x_train.shape[1], \n",
        "                  activation=params['activation'],\n",
        "                  kernel_initializer = params['kernel_initializer']))\n",
        "  # add dropout layer\n",
        "  model.add(Dropout(params['dropout']))\n",
        "  # add output layer\n",
        "  model.add(Dense(1,activation=params['last_activation'],\n",
        "                  kernel_initializer = params['kernel_initializer']))\n",
        "  # compile model\n",
        "  model.compile(loss=params['losses'],\n",
        "                optimizer=params['optimizer'](lr=lr_normalizer(params['lr'], params['optimizer'])),\n",
        "                metrics=['acc', fmeasure_acc])\n",
        "  # train model\n",
        "  out = model.fit(x_train, y_train,\n",
        "                  validation_data=[x_val, y_val],\n",
        "                  batch_size=params['batch_size'],\n",
        "                  # 180*.29 = ~52, which is ~20% of all data\n",
        "                  #val_split = .29, \n",
        "                  epochs=params['epochs'])\n",
        "  return out, model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dI3vgOBzlAPN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set hyperparameters to optimize\n",
        "p = {'first_neuron': [4, 8, 16, 32],\n",
        "     'activation': [relu, sigmoid],\n",
        "     'optimizer': [Nadam, Adam],\n",
        "     'losses':[binary_crossentropy],\n",
        "     'hidden_layers':[0, 1, 2],\n",
        "     'batch_size': [10, 20, 30],\n",
        "     'epochs':[4, 10, 20, 40],\n",
        "     'dropout': [0, 0.1, 0.2],\n",
        "     'kernel_initializer': ['uniform','normal'],\n",
        "     'lr':[0.001, 0.01, 0.1],\n",
        "     'last_activation': ['sigmoid']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KPtOn24CUsEO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5584
        },
        "outputId": "c73871a5-2a9d-4238-95bc-5ed5ef1650e0"
      },
      "cell_type": "code",
      "source": [
        "# starting optimization\n",
        "h = ta.Scan(x= x_train, y=y_train,\n",
        "            params=p,\n",
        "            model=input_model,\n",
        "            grid_downsample=.001)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 125 samples, validate on 55 samples\n",
            "Epoch 1/4\n",
            "125/125 [==============================] - 3s 24ms/step - loss: 0.6756 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6745 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 2/4\n",
            "125/125 [==============================] - 0s 218us/step - loss: 0.6754 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6743 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 3/4\n",
            "125/125 [==============================] - 0s 215us/step - loss: 0.6752 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6740 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 4/4\n",
            "125/125 [==============================] - 0s 234us/step - loss: 0.6749 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6738 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [00:03<00:33,  3.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Train on 125 samples, validate on 55 samples\n",
            "Epoch 1/4\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.7165 - acc: 0.2160 - fmeasure_acc: 0.3352 - val_loss: 0.7170 - val_acc: 0.2000 - val_fmeasure_acc: 0.3249\n",
            "Epoch 2/4\n",
            "125/125 [==============================] - 0s 773us/step - loss: 0.7149 - acc: 0.2000 - fmeasure_acc: 0.3244 - val_loss: 0.7167 - val_acc: 0.2000 - val_fmeasure_acc: 0.3249\n",
            "Epoch 3/4\n",
            "125/125 [==============================] - 0s 532us/step - loss: 0.7132 - acc: 0.2240 - fmeasure_acc: 0.3220 - val_loss: 0.7163 - val_acc: 0.2000 - val_fmeasure_acc: 0.3249\n",
            "Epoch 4/4\n",
            "125/125 [==============================] - 0s 552us/step - loss: 0.7165 - acc: 0.2080 - fmeasure_acc: 0.3261 - val_loss: 0.7160 - val_acc: 0.2000 - val_fmeasure_acc: 0.3249\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:04<00:23,  2.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 125 samples, validate on 55 samples\n",
            "Epoch 1/40\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6706 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6684 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "125/125 [==============================] - 0s 318us/step - loss: 0.6686 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6683 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "125/125 [==============================] - 0s 329us/step - loss: 0.6691 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6682 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "125/125 [==============================] - 0s 294us/step - loss: 0.6680 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6681 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "125/125 [==============================] - 0s 299us/step - loss: 0.6683 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6679 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "125/125 [==============================] - 0s 307us/step - loss: 0.6693 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6678 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "125/125 [==============================] - 0s 314us/step - loss: 0.6692 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6677 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "125/125 [==============================] - 0s 350us/step - loss: 0.6678 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6676 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "125/125 [==============================] - 0s 321us/step - loss: 0.6677 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6674 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "125/125 [==============================] - 0s 397us/step - loss: 0.6670 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6673 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "125/125 [==============================] - 0s 293us/step - loss: 0.6679 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6672 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "125/125 [==============================] - 0s 356us/step - loss: 0.6661 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6670 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "125/125 [==============================] - 0s 318us/step - loss: 0.6672 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6669 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "125/125 [==============================] - 0s 293us/step - loss: 0.6690 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6668 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "125/125 [==============================] - 0s 292us/step - loss: 0.6670 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6667 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "125/125 [==============================] - 0s 314us/step - loss: 0.6674 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6665 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "125/125 [==============================] - 0s 274us/step - loss: 0.6668 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6664 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "125/125 [==============================] - 0s 318us/step - loss: 0.6671 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6663 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "125/125 [==============================] - 0s 327us/step - loss: 0.6688 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6661 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "125/125 [==============================] - 0s 294us/step - loss: 0.6657 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6660 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 21/40\n",
            "125/125 [==============================] - 0s 296us/step - loss: 0.6666 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6658 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 22/40\n",
            "125/125 [==============================] - 0s 327us/step - loss: 0.6663 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6657 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "125/125 [==============================] - 0s 319us/step - loss: 0.6660 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6656 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "125/125 [==============================] - 0s 307us/step - loss: 0.6662 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6654 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 25/40\n",
            "125/125 [==============================] - 0s 280us/step - loss: 0.6662 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6653 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 26/40\n",
            "125/125 [==============================] - 0s 302us/step - loss: 0.6661 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6652 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 27/40\n",
            "125/125 [==============================] - 0s 315us/step - loss: 0.6655 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6651 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 28/40\n",
            "125/125 [==============================] - 0s 339us/step - loss: 0.6647 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6649 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 29/40\n",
            "125/125 [==============================] - 0s 326us/step - loss: 0.6652 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6648 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 30/40\n",
            "125/125 [==============================] - 0s 293us/step - loss: 0.6654 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6647 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 31/40\n",
            "125/125 [==============================] - 0s 311us/step - loss: 0.6651 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6645 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 32/40\n",
            "125/125 [==============================] - 0s 277us/step - loss: 0.6636 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6644 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 33/40\n",
            "125/125 [==============================] - 0s 339us/step - loss: 0.6649 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6643 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 34/40\n",
            "125/125 [==============================] - 0s 293us/step - loss: 0.6646 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6641 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 35/40\n",
            "125/125 [==============================] - 0s 444us/step - loss: 0.6644 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6640 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 36/40\n",
            "125/125 [==============================] - 0s 309us/step - loss: 0.6651 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6639 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 37/40\n",
            "125/125 [==============================] - 0s 342us/step - loss: 0.6658 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6638 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 38/40\n",
            "125/125 [==============================] - 0s 358us/step - loss: 0.6642 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 39/40\n",
            "125/125 [==============================] - 0s 350us/step - loss: 0.6636 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 40/40\n",
            "125/125 [==============================] - 0s 312us/step - loss: 0.6646 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [00:07<00:19,  2.81s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 125 samples, validate on 55 samples\n",
            "Epoch 1/4\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6966 - acc: 0.2880 - fmeasure_acc: 0.3206 - val_loss: 0.6955 - val_acc: 0.2000 - val_fmeasure_acc: 0.3308\n",
            "Epoch 2/4\n",
            "125/125 [==============================] - 0s 434us/step - loss: 0.6952 - acc: 0.2720 - fmeasure_acc: 0.2982 - val_loss: 0.6944 - val_acc: 0.2000 - val_fmeasure_acc: 0.3308\n",
            "Epoch 3/4\n",
            "125/125 [==============================] - 0s 410us/step - loss: 0.6940 - acc: 0.3440 - fmeasure_acc: 0.3262 - val_loss: 0.6933 - val_acc: 0.3091 - val_fmeasure_acc: 0.3499\n",
            "Epoch 4/4\n",
            "125/125 [==============================] - 0s 422us/step - loss: 0.6930 - acc: 0.5120 - fmeasure_acc: 0.2538 - val_loss: 0.6922 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [00:08<00:14,  2.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 125 samples, validate on 55 samples\n",
            "Epoch 1/4\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6836 - acc: 0.7920 - fmeasure_acc: 0.0990 - val_loss: 0.6830 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 2/4\n",
            "125/125 [==============================] - 0s 371us/step - loss: 0.6805 - acc: 0.8000 - fmeasure_acc: 0.0400 - val_loss: 0.6800 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 3/4\n",
            "125/125 [==============================] - 0s 407us/step - loss: 0.6801 - acc: 0.7840 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6767 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 4/4\n",
            "125/125 [==============================] - 0s 391us/step - loss: 0.6762 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6734 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [00:09<00:09,  2.00s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 125 samples, validate on 55 samples\n",
            "Epoch 1/20\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6935 - acc: 0.3600 - fmeasure_acc: 0.2935 - val_loss: 0.6934 - val_acc: 0.4364 - val_fmeasure_acc: 0.3566\n",
            "Epoch 2/20\n",
            "125/125 [==============================] - 0s 709us/step - loss: 0.6931 - acc: 0.5600 - fmeasure_acc: 0.2168 - val_loss: 0.6930 - val_acc: 0.6727 - val_fmeasure_acc: 0.4190\n",
            "Epoch 3/20\n",
            "125/125 [==============================] - 0s 780us/step - loss: 0.6926 - acc: 0.6640 - fmeasure_acc: 0.1853 - val_loss: 0.6926 - val_acc: 0.7273 - val_fmeasure_acc: 0.3152\n",
            "Epoch 4/20\n",
            "125/125 [==============================] - 0s 698us/step - loss: 0.6922 - acc: 0.7120 - fmeasure_acc: 0.1467 - val_loss: 0.6922 - val_acc: 0.7273 - val_fmeasure_acc: 0.1212\n",
            "Epoch 5/20\n",
            "125/125 [==============================] - 0s 720us/step - loss: 0.6918 - acc: 0.7600 - fmeasure_acc: 0.0400 - val_loss: 0.6918 - val_acc: 0.7818 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 6/20\n",
            "125/125 [==============================] - 0s 701us/step - loss: 0.6914 - acc: 0.7920 - fmeasure_acc: 0.0400 - val_loss: 0.6913 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 7/20\n",
            "125/125 [==============================] - 0s 667us/step - loss: 0.6910 - acc: 0.7840 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6909 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 8/20\n",
            "125/125 [==============================] - 0s 672us/step - loss: 0.6906 - acc: 0.7920 - fmeasure_acc: 0.0400 - val_loss: 0.6905 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 9/20\n",
            "125/125 [==============================] - 0s 691us/step - loss: 0.6901 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6901 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 10/20\n",
            "125/125 [==============================] - 0s 693us/step - loss: 0.6896 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6897 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 11/20\n",
            "125/125 [==============================] - 0s 675us/step - loss: 0.6892 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6893 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 12/20\n",
            "125/125 [==============================] - 0s 755us/step - loss: 0.6889 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6889 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 13/20\n",
            "125/125 [==============================] - 0s 695us/step - loss: 0.6884 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6885 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 14/20\n",
            "125/125 [==============================] - 0s 726us/step - loss: 0.6881 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6881 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 15/20\n",
            "125/125 [==============================] - 0s 827us/step - loss: 0.6877 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6877 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 16/20\n",
            "125/125 [==============================] - 0s 726us/step - loss: 0.6871 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6873 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 17/20\n",
            "125/125 [==============================] - 0s 740us/step - loss: 0.6867 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6869 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 18/20\n",
            "125/125 [==============================] - 0s 735us/step - loss: 0.6862 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6865 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 19/20\n",
            "125/125 [==============================] - 0s 728us/step - loss: 0.6857 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6860 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 20/20\n",
            "125/125 [==============================] - 0s 571us/step - loss: 0.6853 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6856 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [00:12<00:09,  2.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 125 samples, validate on 55 samples\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 0.4880 - fmeasure_acc: 0.3195 - val_loss: 0.6929 - val_acc: 0.6182 - val_fmeasure_acc: 0.3231\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 0s 309us/step - loss: 0.6929 - acc: 0.6640 - fmeasure_acc: 0.3957 - val_loss: 0.6927 - val_acc: 0.6364 - val_fmeasure_acc: 0.2727\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 0s 295us/step - loss: 0.6927 - acc: 0.7280 - fmeasure_acc: 0.3253 - val_loss: 0.6926 - val_acc: 0.6727 - val_fmeasure_acc: 0.1948\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 0s 286us/step - loss: 0.6925 - acc: 0.7760 - fmeasure_acc: 0.2024 - val_loss: 0.6924 - val_acc: 0.7455 - val_fmeasure_acc: 0.1136\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 0s 301us/step - loss: 0.6923 - acc: 0.7680 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6922 - val_acc: 0.7455 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 0s 297us/step - loss: 0.6921 - acc: 0.7840 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6920 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 0s 316us/step - loss: 0.6919 - acc: 0.7840 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6918 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 0s 338us/step - loss: 0.6917 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6916 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 0s 309us/step - loss: 0.6915 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6914 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 0s 292us/step - loss: 0.6913 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6913 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [00:13<00:05,  1.95s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 125 samples, validate on 55 samples\n",
            "Epoch 1/20\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6935 - acc: 0.3760 - fmeasure_acc: 0.3458 - val_loss: 0.6935 - val_acc: 0.3273 - val_fmeasure_acc: 0.2298\n",
            "Epoch 2/20\n",
            "125/125 [==============================] - 0s 695us/step - loss: 0.6935 - acc: 0.3520 - fmeasure_acc: 0.2945 - val_loss: 0.6934 - val_acc: 0.3273 - val_fmeasure_acc: 0.2298\n",
            "Epoch 3/20\n",
            "125/125 [==============================] - 0s 725us/step - loss: 0.6934 - acc: 0.3520 - fmeasure_acc: 0.2922 - val_loss: 0.6934 - val_acc: 0.3455 - val_fmeasure_acc: 0.2088\n",
            "Epoch 4/20\n",
            "125/125 [==============================] - 0s 709us/step - loss: 0.6933 - acc: 0.4160 - fmeasure_acc: 0.3168 - val_loss: 0.6933 - val_acc: 0.3818 - val_fmeasure_acc: 0.2088\n",
            "Epoch 5/20\n",
            "125/125 [==============================] - 0s 711us/step - loss: 0.6933 - acc: 0.4480 - fmeasure_acc: 0.2804 - val_loss: 0.6933 - val_acc: 0.4000 - val_fmeasure_acc: 0.2169\n",
            "Epoch 6/20\n",
            "125/125 [==============================] - 0s 775us/step - loss: 0.6932 - acc: 0.4960 - fmeasure_acc: 0.3658 - val_loss: 0.6932 - val_acc: 0.4364 - val_fmeasure_acc: 0.2283\n",
            "Epoch 7/20\n",
            "125/125 [==============================] - 0s 735us/step - loss: 0.6932 - acc: 0.5360 - fmeasure_acc: 0.3300 - val_loss: 0.6931 - val_acc: 0.4545 - val_fmeasure_acc: 0.2121\n",
            "Epoch 8/20\n",
            "125/125 [==============================] - 0s 707us/step - loss: 0.6931 - acc: 0.5280 - fmeasure_acc: 0.3292 - val_loss: 0.6931 - val_acc: 0.4727 - val_fmeasure_acc: 0.2121\n",
            "Epoch 9/20\n",
            "125/125 [==============================] - 0s 656us/step - loss: 0.6930 - acc: 0.5920 - fmeasure_acc: 0.3554 - val_loss: 0.6930 - val_acc: 0.5455 - val_fmeasure_acc: 0.2251\n",
            "Epoch 10/20\n",
            "125/125 [==============================] - 0s 732us/step - loss: 0.6930 - acc: 0.6000 - fmeasure_acc: 0.3092 - val_loss: 0.6930 - val_acc: 0.6000 - val_fmeasure_acc: 0.2442\n",
            "Epoch 11/20\n",
            "125/125 [==============================] - 0s 715us/step - loss: 0.6929 - acc: 0.6000 - fmeasure_acc: 0.3156 - val_loss: 0.6929 - val_acc: 0.6000 - val_fmeasure_acc: 0.2442\n",
            "Epoch 12/20\n",
            "125/125 [==============================] - 0s 680us/step - loss: 0.6929 - acc: 0.6400 - fmeasure_acc: 0.3226 - val_loss: 0.6929 - val_acc: 0.6364 - val_fmeasure_acc: 0.2442\n",
            "Epoch 13/20\n",
            "125/125 [==============================] - 0s 667us/step - loss: 0.6929 - acc: 0.6000 - fmeasure_acc: 0.3250 - val_loss: 0.6928 - val_acc: 0.6727 - val_fmeasure_acc: 0.2615\n",
            "Epoch 14/20\n",
            "125/125 [==============================] - 0s 651us/step - loss: 0.6927 - acc: 0.6400 - fmeasure_acc: 0.3510 - val_loss: 0.6928 - val_acc: 0.6727 - val_fmeasure_acc: 0.2615\n",
            "Epoch 15/20\n",
            "125/125 [==============================] - 0s 672us/step - loss: 0.6927 - acc: 0.7040 - fmeasure_acc: 0.3174 - val_loss: 0.6927 - val_acc: 0.6909 - val_fmeasure_acc: 0.2667\n",
            "Epoch 16/20\n",
            "125/125 [==============================] - 0s 579us/step - loss: 0.6926 - acc: 0.6720 - fmeasure_acc: 0.3356 - val_loss: 0.6927 - val_acc: 0.7091 - val_fmeasure_acc: 0.2667\n",
            "Epoch 17/20\n",
            "125/125 [==============================] - 0s 566us/step - loss: 0.6927 - acc: 0.6960 - fmeasure_acc: 0.2853 - val_loss: 0.6926 - val_acc: 0.7091 - val_fmeasure_acc: 0.2667\n",
            "Epoch 18/20\n",
            "125/125 [==============================] - 0s 719us/step - loss: 0.6925 - acc: 0.7120 - fmeasure_acc: 0.2964 - val_loss: 0.6926 - val_acc: 0.7455 - val_fmeasure_acc: 0.2667\n",
            "Epoch 19/20\n",
            "125/125 [==============================] - 0s 568us/step - loss: 0.6925 - acc: 0.7040 - fmeasure_acc: 0.2990 - val_loss: 0.6925 - val_acc: 0.7455 - val_fmeasure_acc: 0.2667\n",
            "Epoch 20/20\n",
            "125/125 [==============================] - 0s 568us/step - loss: 0.6924 - acc: 0.7520 - fmeasure_acc: 0.2819 - val_loss: 0.6925 - val_acc: 0.7818 - val_fmeasure_acc: 0.2667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [00:16<00:04,  2.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 125 samples, validate on 55 samples\n",
            "Epoch 1/4\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6937 - acc: 0.4480 - fmeasure_acc: 0.2650 - val_loss: 0.6947 - val_acc: 0.3273 - val_fmeasure_acc: 0.2744\n",
            "Epoch 2/4\n",
            "125/125 [==============================] - 0s 302us/step - loss: 0.6937 - acc: 0.4560 - fmeasure_acc: 0.2883 - val_loss: 0.6947 - val_acc: 0.3273 - val_fmeasure_acc: 0.2744\n",
            "Epoch 3/4\n",
            "125/125 [==============================] - 0s 318us/step - loss: 0.6937 - acc: 0.4560 - fmeasure_acc: 0.2427 - val_loss: 0.6947 - val_acc: 0.3273 - val_fmeasure_acc: 0.2744\n",
            "Epoch 4/4\n",
            "125/125 [==============================] - 0s 300us/step - loss: 0.6938 - acc: 0.4560 - fmeasure_acc: 0.2593 - val_loss: 0.6947 - val_acc: 0.3273 - val_fmeasure_acc: 0.2744\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [00:17<00:01,  1.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 125 samples, validate on 55 samples\n",
            "Epoch 1/40\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6642 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "125/125 [==============================] - 0s 360us/step - loss: 0.6642 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "125/125 [==============================] - 0s 370us/step - loss: 0.6642 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "125/125 [==============================] - 0s 366us/step - loss: 0.6641 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "125/125 [==============================] - 0s 424us/step - loss: 0.6641 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "125/125 [==============================] - 0s 409us/step - loss: 0.6641 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "125/125 [==============================] - 0s 319us/step - loss: 0.6641 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "125/125 [==============================] - 0s 377us/step - loss: 0.6640 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "125/125 [==============================] - 0s 405us/step - loss: 0.6640 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6634 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "125/125 [==============================] - 0s 394us/step - loss: 0.6640 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "125/125 [==============================] - 0s 367us/step - loss: 0.6639 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "125/125 [==============================] - 0s 359us/step - loss: 0.6639 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6633 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "125/125 [==============================] - 0s 390us/step - loss: 0.6639 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "125/125 [==============================] - 0s 428us/step - loss: 0.6638 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "125/125 [==============================] - 0s 361us/step - loss: 0.6638 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6632 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "125/125 [==============================] - 0s 380us/step - loss: 0.6638 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "125/125 [==============================] - 0s 394us/step - loss: 0.6638 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "125/125 [==============================] - 0s 378us/step - loss: 0.6637 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6631 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "125/125 [==============================] - 0s 384us/step - loss: 0.6637 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "125/125 [==============================] - 0s 381us/step - loss: 0.6637 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 21/40\n",
            "125/125 [==============================] - 0s 352us/step - loss: 0.6636 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 22/40\n",
            "125/125 [==============================] - 0s 382us/step - loss: 0.6636 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "125/125 [==============================] - 0s 382us/step - loss: 0.6636 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "125/125 [==============================] - 0s 378us/step - loss: 0.6635 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 25/40\n",
            "125/125 [==============================] - 0s 375us/step - loss: 0.6635 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 26/40\n",
            "125/125 [==============================] - 0s 434us/step - loss: 0.6635 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 27/40\n",
            "125/125 [==============================] - 0s 430us/step - loss: 0.6635 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 28/40\n",
            "125/125 [==============================] - 0s 371us/step - loss: 0.6634 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6628 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 29/40\n",
            "125/125 [==============================] - 0s 395us/step - loss: 0.6634 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 30/40\n",
            "125/125 [==============================] - 0s 416us/step - loss: 0.6634 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 31/40\n",
            "125/125 [==============================] - 0s 398us/step - loss: 0.6633 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 32/40\n",
            "125/125 [==============================] - 0s 379us/step - loss: 0.6633 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6627 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 33/40\n",
            "125/125 [==============================] - 0s 408us/step - loss: 0.6633 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 34/40\n",
            "125/125 [==============================] - 0s 585us/step - loss: 0.6632 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 35/40\n",
            "125/125 [==============================] - 0s 382us/step - loss: 0.6632 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6626 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 36/40\n",
            "125/125 [==============================] - 0s 367us/step - loss: 0.6632 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 37/40\n",
            "125/125 [==============================] - 0s 356us/step - loss: 0.6632 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 38/40\n",
            "125/125 [==============================] - 0s 387us/step - loss: 0.6631 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6625 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 39/40\n",
            "125/125 [==============================] - 0s 383us/step - loss: 0.6631 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n",
            "Epoch 40/40\n",
            "125/125 [==============================] - 0s 407us/step - loss: 0.6631 - acc: 0.7920 - fmeasure_acc: 0.0000e+00 - val_loss: 0.6624 - val_acc: 0.8000 - val_fmeasure_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 10/10 [00:20<00:00,  2.20s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "3jLhYJQ4t5lQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "20c5e39b-8792-4de0-bced-aa114b4b5a68"
      },
      "cell_type": "code",
      "source": [
        "# accessing the results data frame\n",
        "h.data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>round_epochs</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_acc</th>\n",
              "      <th>val_fmeasure_acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>fmeasure_acc</th>\n",
              "      <th>first_neuron</th>\n",
              "      <th>activation</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>losses</th>\n",
              "      <th>hidden_layers</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>dropout</th>\n",
              "      <th>kernel_initializer</th>\n",
              "      <th>lr</th>\n",
              "      <th>last_activation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>0.673808</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.674917</td>\n",
              "      <td>0.792</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>32</td>\n",
              "      <td>&lt;function sigmoid at 0x7f708d2d8840&gt;</td>\n",
              "      <td>&lt;class 'keras.optimizers.Adam'&gt;</td>\n",
              "      <td>&lt;function binary_crossentropy at 0x7f708d326840&gt;</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>normal</td>\n",
              "      <td>0.01</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>0.715969</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.324857</td>\n",
              "      <td>0.713250</td>\n",
              "      <td>0.224</td>\n",
              "      <td>0.335161</td>\n",
              "      <td>16</td>\n",
              "      <td>&lt;function sigmoid at 0x7f708d2d8840&gt;</td>\n",
              "      <td>&lt;class 'keras.optimizers.Adam'&gt;</td>\n",
              "      <td>&lt;function binary_crossentropy at 0x7f708d326840&gt;</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>normal</td>\n",
              "      <td>0.01</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40</td>\n",
              "      <td>0.663364</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.663591</td>\n",
              "      <td>0.792</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>&lt;function sigmoid at 0x7f708d2d8840&gt;</td>\n",
              "      <td>&lt;class 'keras.optimizers.Nadam'&gt;</td>\n",
              "      <td>&lt;function binary_crossentropy at 0x7f708d326840&gt;</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>40</td>\n",
              "      <td>0.1</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.01</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.692159</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.349885</td>\n",
              "      <td>0.693015</td>\n",
              "      <td>0.512</td>\n",
              "      <td>0.326171</td>\n",
              "      <td>4</td>\n",
              "      <td>&lt;function sigmoid at 0x7f708d2d8840&gt;</td>\n",
              "      <td>&lt;class 'keras.optimizers.Nadam'&gt;</td>\n",
              "      <td>&lt;function binary_crossentropy at 0x7f708d326840&gt;</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.10</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.673400</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.676160</td>\n",
              "      <td>0.800</td>\n",
              "      <td>0.099048</td>\n",
              "      <td>16</td>\n",
              "      <td>&lt;function sigmoid at 0x7f708d2d8840&gt;</td>\n",
              "      <td>&lt;class 'keras.optimizers.Nadam'&gt;</td>\n",
              "      <td>&lt;function binary_crossentropy at 0x7f708d326840&gt;</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.10</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   round_epochs  val_loss  val_acc  val_fmeasure_acc      loss    acc  \\\n",
              "0             4  0.673808      0.8          0.000000  0.674917  0.792   \n",
              "1             4  0.715969      0.2          0.324857  0.713250  0.224   \n",
              "2            40  0.663364      0.8          0.000000  0.663591  0.792   \n",
              "3             4  0.692159      0.8          0.349885  0.693015  0.512   \n",
              "4             4  0.673400      0.8          0.000000  0.676160  0.800   \n",
              "\n",
              "   fmeasure_acc  first_neuron                            activation  \\\n",
              "0      0.000000            32  <function sigmoid at 0x7f708d2d8840>   \n",
              "1      0.335161            16  <function sigmoid at 0x7f708d2d8840>   \n",
              "2      0.000000             8  <function sigmoid at 0x7f708d2d8840>   \n",
              "3      0.326171             4  <function sigmoid at 0x7f708d2d8840>   \n",
              "4      0.099048            16  <function sigmoid at 0x7f708d2d8840>   \n",
              "\n",
              "                          optimizer  \\\n",
              "0   <class 'keras.optimizers.Adam'>   \n",
              "1   <class 'keras.optimizers.Adam'>   \n",
              "2  <class 'keras.optimizers.Nadam'>   \n",
              "3  <class 'keras.optimizers.Nadam'>   \n",
              "4  <class 'keras.optimizers.Nadam'>   \n",
              "\n",
              "                                             losses  hidden_layers  \\\n",
              "0  <function binary_crossentropy at 0x7f708d326840>              1   \n",
              "1  <function binary_crossentropy at 0x7f708d326840>              1   \n",
              "2  <function binary_crossentropy at 0x7f708d326840>              1   \n",
              "3  <function binary_crossentropy at 0x7f708d326840>              2   \n",
              "4  <function binary_crossentropy at 0x7f708d326840>              1   \n",
              "\n",
              "   batch_size  epochs  dropout kernel_initializer    lr last_activation  \n",
              "0          30       4      0.0             normal  0.01         sigmoid  \n",
              "1          10       4      0.1             normal  0.01         sigmoid  \n",
              "2          30      40      0.1            uniform  0.01         sigmoid  \n",
              "3          20       4      0.1            uniform  0.10         sigmoid  \n",
              "4          20       4      0.1            uniform  0.10         sigmoid  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "P_eM9y8RiyfJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Best model based on training criteria \"val_acc\"\n",
        "best_model = h.best_model(metric='val_acc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jps9bGEtuC0w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "21d7fd2d-20d1-41d7-85cf-10695a5c580c"
      },
      "cell_type": "code",
      "source": [
        "# accessing epoch entropy values for each round\n",
        "h.peak_epochs_df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_acc</th>\n",
              "      <th>val_fmeasure_acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>fmeasure_acc</th>\n",
              "      <th>acc_epoch</th>\n",
              "      <th>loss_epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-5.579151e-17</td>\n",
              "      <td>4.573270e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>8.912983e-04</td>\n",
              "      <td>1.781976e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>39</td>\n",
              "      <td>39</td>\n",
              "      <td>39</td>\n",
              "      <td>31</td>\n",
              "      <td>30</td>\n",
              "      <td>39</td>\n",
              "      <td>1.343987e-16</td>\n",
              "      <td>6.234624e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>6.192039e-02</td>\n",
              "      <td>2.005898e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.550888e-05</td>\n",
              "      <td>1.817601e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1.079944e-03</td>\n",
              "      <td>1.742530e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2.689707e-03</td>\n",
              "      <td>2.043705e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>5</td>\n",
              "      <td>2.776147e-03</td>\n",
              "      <td>1.969397e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2.928282e-05</td>\n",
              "      <td>1.566126e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>39</td>\n",
              "      <td>39</td>\n",
              "      <td>39</td>\n",
              "      <td>39</td>\n",
              "      <td>35</td>\n",
              "      <td>39</td>\n",
              "      <td>2.691666e-17</td>\n",
              "      <td>3.909669e-11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   val_loss val_acc val_fmeasure_acc loss acc fmeasure_acc     acc_epoch  \\\n",
              "1         3       3                3    3   2            3 -5.579151e-17   \n",
              "2         3       3                3    2   2            0  8.912983e-04   \n",
              "3        39      39               39   31  30           39  1.343987e-16   \n",
              "4         3       3                2    3   3            2  6.192039e-02   \n",
              "5         3       3                3    3   1            0  2.550888e-05   \n",
              "6        19      19                1   19   5            0  1.079944e-03   \n",
              "7         9       9                0    9   7            1  2.689707e-03   \n",
              "8        19      19               19   19  19            5  2.776147e-03   \n",
              "9         3       3                3    2   3            1  2.928282e-05   \n",
              "10       39      39               39   39  35           39  2.691666e-17   \n",
              "\n",
              "      loss_epoch  \n",
              "1   4.573270e-11  \n",
              "2   1.781976e-06  \n",
              "3   6.234624e-07  \n",
              "4   2.005898e-08  \n",
              "5   1.817601e-06  \n",
              "6   1.742530e-08  \n",
              "7   2.043705e-09  \n",
              "8   1.969397e-09  \n",
              "9   1.566126e-09  \n",
              "10  3.909669e-11  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "6n2YlqKLuH1R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "945784a2-1bb8-42a9-ea15-90f52ce9a177"
      },
      "cell_type": "code",
      "source": [
        "# access the summary details\n",
        "h.details"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "random_method          uniform_mersenne\n",
              "reduction_method                   None\n",
              "reduction_interval                   50\n",
              "reduction_window                     20\n",
              "grid_downsample                   0.001\n",
              "reduction_threshold                 0.2\n",
              "reduction_metric                val_acc\n",
              "reduce_loss                       False\n",
              "experiment_name           041519141558_\n",
              "complete_time            04/15/19/14:16\n",
              "x_shape                      (180, 200)\n",
              "y_shape                          (180,)\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "TuCWhUXauTNt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "6c8d1488-98fc-4aca-cddd-8886aac91465"
      },
      "cell_type": "code",
      "source": [
        "# accessing the saved models\n",
        "h.saved_models[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_1\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"batch_input_shape\": [null, 200], \"dtype\": \"float32\", \"units\": 32, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"RandomNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.05, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_1\", \"trainable\": true, \"rate\": 0.0, \"noise_shape\": null, \"seed\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"units\": 1, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"RandomNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.05, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.2.4\", \"backend\": \"tensorflow\"}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "iIySufgBuWNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "outputId": "ba8c5983-b9d0-45a2-8a05-98178b22c103"
      },
      "cell_type": "code",
      "source": [
        "# accessing the saved weights for models\n",
        "h.saved_weights[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-1.5504115e-02,  3.8878426e-03,  8.7533459e-02, ...,\n",
              "          2.4995238e-03,  2.6606908e-02, -5.2861843e-02],\n",
              "        [ 2.4652418e-02, -1.1545826e-01,  3.2242130e-02, ...,\n",
              "          4.4823869e-04, -9.6932516e-02, -3.3947691e-02],\n",
              "        [ 1.2177426e-02, -5.1329322e-03,  1.9165458e-02, ...,\n",
              "          4.4482771e-02, -8.4633753e-02,  4.1414011e-02],\n",
              "        ...,\n",
              "        [ 8.1212394e-02, -3.0108670e-02, -8.0518350e-03, ...,\n",
              "          2.1253228e-03,  1.0025525e-01, -9.8016575e-02],\n",
              "        [ 5.6933537e-02, -8.1771612e-03, -1.1432476e-04, ...,\n",
              "          2.5697306e-02,  2.1992780e-02, -8.4980195e-03],\n",
              "        [ 6.4491525e-02,  2.8621262e-02, -8.0150381e-02, ...,\n",
              "         -5.9528198e-02,  3.4931384e-02, -6.1381827e-03]], dtype=float32),\n",
              " array([-0.00018658,  0.00019664,  0.00019672, -0.00019623, -0.00019656,\n",
              "        -0.00019637,  0.00019667,  0.00019669, -0.00019667,  0.00019672,\n",
              "         0.00019669, -0.00019658,  0.00019672, -0.00019664, -0.00019642,\n",
              "         0.00019671, -0.00019642,  0.00019662,  0.00019672, -0.00019665,\n",
              "         0.00019658,  0.00019669,  0.00019672, -0.00019608, -0.00019652,\n",
              "        -0.0001957 , -0.00019668,  0.00019651, -0.00019663,  0.00019671,\n",
              "        -0.00019646, -0.00019653], dtype=float32),\n",
              " array([[ 0.00041086],\n",
              "        [-0.01077248],\n",
              "        [-0.06843471],\n",
              "        [ 0.01117927],\n",
              "        [ 0.03229481],\n",
              "        [ 0.01539708],\n",
              "        [-0.01514218],\n",
              "        [-0.02404671],\n",
              "        [ 0.08993984],\n",
              "        [-0.06049369],\n",
              "        [-0.02383694],\n",
              "        [ 0.03712425],\n",
              "        [-0.09832423],\n",
              "        [ 0.06016709],\n",
              "        [ 0.01779344],\n",
              "        [-0.05612478],\n",
              "        [ 0.01793789],\n",
              "        [-0.00906727],\n",
              "        [-0.09388889],\n",
              "        [ 0.06691787],\n",
              "        [-0.00677412],\n",
              "        [-0.0242716 ],\n",
              "        [-0.18180272],\n",
              "        [ 0.00848943],\n",
              "        [ 0.02611648],\n",
              "        [ 0.00527836],\n",
              "        [ 0.11484578],\n",
              "        [-0.00462524],\n",
              "        [ 0.05364643],\n",
              "        [-0.05799765],\n",
              "        [ 0.02105957],\n",
              "        [ 0.02838195]], dtype=float32),\n",
              " array([-0.00019673], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "yF0EJL-cfvB7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reporting \n",
        "In the Scan process, the results are stored round-by-round in the corresponding experiment log which is a .csv file stored in the present working directory. The Reporting() accepts as its source either a file name, or the Scan object.\n",
        "\n",
        "**See source code to dcide how to use this command** \n",
        "https://github.com/autonomio/talos/blob/daily-dev/talos/commands/reporting.py "
      ]
    },
    {
      "metadata": {
        "id": "vUSL0U1muiuK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# use Scan object as input\n",
        "r = ta.Reporting(h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZT5SHcUdux56",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "outputId": "8c85eaf3-8a48-412d-c344-a08b76b4c15d"
      },
      "cell_type": "code",
      "source": [
        "# access the dataframe with the results\n",
        "r.data.head(-3)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>round_epochs</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_acc</th>\n",
              "      <th>val_fmeasure_acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>fmeasure_acc</th>\n",
              "      <th>first_neuron</th>\n",
              "      <th>activation</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>losses</th>\n",
              "      <th>hidden_layers</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>dropout</th>\n",
              "      <th>kernel_initializer</th>\n",
              "      <th>lr</th>\n",
              "      <th>last_activation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>0.673808</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.674917</td>\n",
              "      <td>0.792</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>32</td>\n",
              "      <td>&lt;function sigmoid at 0x7f708d2d8840&gt;</td>\n",
              "      <td>&lt;class 'keras.optimizers.Adam'&gt;</td>\n",
              "      <td>&lt;function binary_crossentropy at 0x7f708d326840&gt;</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>normal</td>\n",
              "      <td>0.01</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>0.715969</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.324857</td>\n",
              "      <td>0.713250</td>\n",
              "      <td>0.224</td>\n",
              "      <td>0.335161</td>\n",
              "      <td>16</td>\n",
              "      <td>&lt;function sigmoid at 0x7f708d2d8840&gt;</td>\n",
              "      <td>&lt;class 'keras.optimizers.Adam'&gt;</td>\n",
              "      <td>&lt;function binary_crossentropy at 0x7f708d326840&gt;</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>normal</td>\n",
              "      <td>0.01</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40</td>\n",
              "      <td>0.663364</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.663591</td>\n",
              "      <td>0.792</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>&lt;function sigmoid at 0x7f708d2d8840&gt;</td>\n",
              "      <td>&lt;class 'keras.optimizers.Nadam'&gt;</td>\n",
              "      <td>&lt;function binary_crossentropy at 0x7f708d326840&gt;</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>40</td>\n",
              "      <td>0.1</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.01</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.692159</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.349885</td>\n",
              "      <td>0.693015</td>\n",
              "      <td>0.512</td>\n",
              "      <td>0.326171</td>\n",
              "      <td>4</td>\n",
              "      <td>&lt;function sigmoid at 0x7f708d2d8840&gt;</td>\n",
              "      <td>&lt;class 'keras.optimizers.Nadam'&gt;</td>\n",
              "      <td>&lt;function binary_crossentropy at 0x7f708d326840&gt;</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.10</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.673400</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.676160</td>\n",
              "      <td>0.800</td>\n",
              "      <td>0.099048</td>\n",
              "      <td>16</td>\n",
              "      <td>&lt;function sigmoid at 0x7f708d2d8840&gt;</td>\n",
              "      <td>&lt;class 'keras.optimizers.Nadam'&gt;</td>\n",
              "      <td>&lt;function binary_crossentropy at 0x7f708d326840&gt;</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.10</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>20</td>\n",
              "      <td>0.685601</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.419048</td>\n",
              "      <td>0.685337</td>\n",
              "      <td>0.792</td>\n",
              "      <td>0.293524</td>\n",
              "      <td>8</td>\n",
              "      <td>&lt;function relu at 0x7f708d2d8730&gt;</td>\n",
              "      <td>&lt;class 'keras.optimizers.Adam'&gt;</td>\n",
              "      <td>&lt;function binary_crossentropy at 0x7f708d326840&gt;</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>20</td>\n",
              "      <td>0.1</td>\n",
              "      <td>normal</td>\n",
              "      <td>0.10</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10</td>\n",
              "      <td>0.691251</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.323147</td>\n",
              "      <td>0.691289</td>\n",
              "      <td>0.792</td>\n",
              "      <td>0.395702</td>\n",
              "      <td>16</td>\n",
              "      <td>&lt;function relu at 0x7f708d2d8730&gt;</td>\n",
              "      <td>&lt;class 'keras.optimizers.Adam'&gt;</td>\n",
              "      <td>&lt;function binary_crossentropy at 0x7f708d326840&gt;</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.10</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   round_epochs  val_loss  val_acc  val_fmeasure_acc      loss    acc  \\\n",
              "0             4  0.673808      0.8          0.000000  0.674917  0.792   \n",
              "1             4  0.715969      0.2          0.324857  0.713250  0.224   \n",
              "2            40  0.663364      0.8          0.000000  0.663591  0.792   \n",
              "3             4  0.692159      0.8          0.349885  0.693015  0.512   \n",
              "4             4  0.673400      0.8          0.000000  0.676160  0.800   \n",
              "5            20  0.685601      0.8          0.419048  0.685337  0.792   \n",
              "6            10  0.691251      0.8          0.323147  0.691289  0.792   \n",
              "\n",
              "   fmeasure_acc  first_neuron                            activation  \\\n",
              "0      0.000000            32  <function sigmoid at 0x7f708d2d8840>   \n",
              "1      0.335161            16  <function sigmoid at 0x7f708d2d8840>   \n",
              "2      0.000000             8  <function sigmoid at 0x7f708d2d8840>   \n",
              "3      0.326171             4  <function sigmoid at 0x7f708d2d8840>   \n",
              "4      0.099048            16  <function sigmoid at 0x7f708d2d8840>   \n",
              "5      0.293524             8     <function relu at 0x7f708d2d8730>   \n",
              "6      0.395702            16     <function relu at 0x7f708d2d8730>   \n",
              "\n",
              "                          optimizer  \\\n",
              "0   <class 'keras.optimizers.Adam'>   \n",
              "1   <class 'keras.optimizers.Adam'>   \n",
              "2  <class 'keras.optimizers.Nadam'>   \n",
              "3  <class 'keras.optimizers.Nadam'>   \n",
              "4  <class 'keras.optimizers.Nadam'>   \n",
              "5   <class 'keras.optimizers.Adam'>   \n",
              "6   <class 'keras.optimizers.Adam'>   \n",
              "\n",
              "                                             losses  hidden_layers  \\\n",
              "0  <function binary_crossentropy at 0x7f708d326840>              1   \n",
              "1  <function binary_crossentropy at 0x7f708d326840>              1   \n",
              "2  <function binary_crossentropy at 0x7f708d326840>              1   \n",
              "3  <function binary_crossentropy at 0x7f708d326840>              2   \n",
              "4  <function binary_crossentropy at 0x7f708d326840>              1   \n",
              "5  <function binary_crossentropy at 0x7f708d326840>              2   \n",
              "6  <function binary_crossentropy at 0x7f708d326840>              1   \n",
              "\n",
              "   batch_size  epochs  dropout kernel_initializer    lr last_activation  \n",
              "0          30       4      0.0             normal  0.01         sigmoid  \n",
              "1          10       4      0.1             normal  0.01         sigmoid  \n",
              "2          30      40      0.1            uniform  0.01         sigmoid  \n",
              "3          20       4      0.1            uniform  0.10         sigmoid  \n",
              "4          20       4      0.1            uniform  0.10         sigmoid  \n",
              "5          10      20      0.1             normal  0.10         sigmoid  \n",
              "6          30      10      0.0            uniform  0.10         sigmoid  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "-Os1t3GKu5VA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5fbed6ed-342e-4578-9005-4d0564692f05"
      },
      "cell_type": "code",
      "source": [
        "# get the number of rounds in the Scan\n",
        "r.rounds()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "SmBCauXmu74R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ff92c41a-3230-4148-cc3c-439dee4cc9fc"
      },
      "cell_type": "code",
      "source": [
        "# get the highest result ('val_acc' by default)\n",
        "r.high()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.800000011920929"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "_ZPQqpf9u_FK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "294b29db-2466-4e78-9c1e-7e2d55c5660e"
      },
      "cell_type": "code",
      "source": [
        "# get the highest result for any metric\n",
        "print(\"F-measure accuracy:\", r.high('val_fmeasure_acc'))\n",
        "print(\"Training accuracy:\", r.high('acc'))\n",
        "print(\"Validation accuracy:\", r.high('val_acc'))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-measure accuracy: 0.4190475723960183\n",
            "Training accuracy: 0.8000000023841858\n",
            "Validation accuracy: 0.800000011920929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hf-EDDDgvBFs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "46bc06e8-3d61-43b9-fcda-cc2b132d4213"
      },
      "cell_type": "code",
      "source": [
        "# get the round with the best result\n",
        "r.rounds2high()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "RGlss-RFvKYt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "e28a8302-e34a-4244-8a0e-f68e5331d9d5"
      },
      "cell_type": "code",
      "source": [
        "# get the best paramaters\n",
        "r.best_params(n=3) # return the best 3 sets of params"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, '<function sigmoid at 0x7f708d2d8840>', 'sigmoid', 4,\n",
              "        '<function binary_crossentropy at 0x7f708d326840>', 32, 1, 0.01,\n",
              "        30, 0.0, \"<class 'keras.optimizers.Adam'>\", 'normal', 0],\n",
              "       [2, '<function sigmoid at 0x7f708d2d8840>', 'sigmoid', 40,\n",
              "        '<function binary_crossentropy at 0x7f708d326840>', 8, 1, 0.01,\n",
              "        30, 0.1, \"<class 'keras.optimizers.Nadam'>\", 'uniform', 1],\n",
              "       [6, '<function relu at 0x7f708d2d8730>', 'sigmoid', 10,\n",
              "        '<function binary_crossentropy at 0x7f708d326840>', 16, 1, 0.1,\n",
              "        30, 0.0, \"<class 'keras.optimizers.Adam'>\", 'uniform', 2]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "id": "jsmR6_o0vZXh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "683a6c02-7d5a-4f6b-f806-f9bf35b3b07b"
      },
      "cell_type": "code",
      "source": [
        "# get correlation for hyperparameters against a metric\n",
        "print(\"Hyperparameters and validation loss\")\n",
        "print(r.correlate('val_loss'),\"\\n\")\n",
        "print(\"Hyperparameters and validation accuracy\")\n",
        "print(r.correlate('val_acc'))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hyperparameters and validation loss\n",
            "first_neuron    -0.210870\n",
            "hidden_layers   -0.186751\n",
            "batch_size      -0.427704\n",
            "epochs          -0.632774\n",
            "dropout          0.364396\n",
            "lr               0.070279\n",
            "Name: val_loss, dtype: float64 \n",
            "\n",
            "Hyperparameters and validation accuracy\n",
            "first_neuron     0.087708\n",
            "hidden_layers    0.331261\n",
            "batch_size       0.142138\n",
            "epochs           0.390944\n",
            "dropout         -0.331261\n",
            "lr               0.422054\n",
            "Name: val_acc, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4GaRG2g5vhxl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "a35d2565-4957-47cf-ea49-6c33fb5744fb"
      },
      "cell_type": "code",
      "source": [
        "# a regression plot for two dimensions \n",
        "r.plot_regs(\"val_acc\", \"epochs\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsQAAAHPCAYAAABUeszdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQNEEMQAARRPEAAAU7f8CINT/H2BUHN4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x475.2 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "BwlX1zsFaEz2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "outputId": "65b93b90-be08-4412-a436-6afb455d1b22"
      },
      "cell_type": "code",
      "source": [
        "# line plot\n",
        "print(r.plot_line(\"val_acc\"))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1QAAAHPCAYAAABUX5v0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x475.2 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ZRgsw8x5wEnx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "82c598ee-4c4c-4f90-d993-cda382bdfd13"
      },
      "cell_type": "code",
      "source": [
        "# up to two dimensional kernel density estimator\n",
        "r.plot_kde(\"epochs\",\"val_acc\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsQAAAHPCAYAAABUeszdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAwCQNEEMAEDSBDEAAEn7fx2MBrLSmvpZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x475.2 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "rMRhX83oxIv4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "3d930594-894b-47d8-862b-50b577e60d1a"
      },
      "cell_type": "code",
      "source": [
        "# a simple histogram\n",
        "r.plot_hist(bins=50)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsQAAAHPCAYAAABUeszdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDVBDABAaoIYAIDUBDEAAKkJYgAAUvv/TfLmZeIzMyYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x475.2 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "QsM9EKRxxNf1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "4eb4cc2e-667e-400e-85e2-d1f2e12eba34"
      },
      "cell_type": "code",
      "source": [
        "# a four dimensional bar grid\n",
        "r.plot_bars('batch_size', 'val_acc', 'first_neuron', 'lr')\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABL4AAAEUCAYAAAAlXf8jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDuM5sgJtCa0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1218.25x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "nJzqujxIdWgy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "dc553f98-9803-4c4a-d8c2-cbce0bd3d2b1"
      },
      "cell_type": "code",
      "source": [
        "e = ta.Evaluate(h)\n",
        "\n",
        "e.evaluate(x=x_test, y=y_test,\n",
        "           folds=10,\n",
        "           shuffle=True,\n",
        "           metric='val_acc',\n",
        "           mode='binary',\n",
        "           print_out=True)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean : 0.00 \n",
            " std : 0.00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "J90p7EWnyRuf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from talos import Predict\n",
        "\n",
        "p = Predict(h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9YNRNJRly0Tu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1369
        },
        "outputId": "5e1f45bb-08ee-43b0-e2b8-ff8a604fa68d"
      },
      "cell_type": "code",
      "source": [
        "# returns predictions for input x\n",
        "p.predict_classes(x_test, metric='fmeasure_acc')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "SXdtsIOHBZWj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Resources\n",
        "- Talos example:  https://nbviewer.jupyter.org/github/autonomio/talos/blob/master/examples/Hyperparameter%20Optimization%20on%20Keras%20with%20Breast%20Cancer%20Data.ipynb"
      ]
    }
  ]
}